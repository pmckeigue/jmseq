---
title: "R package `jmseq`: fitting joint models of longitudinal and time to event data by sequential Bayesian updating"
author: Paul McKeigue
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{jmseq}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r opts, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
  )

# devtools::check(vignettes=FALSE)
# devtools::document()
# devtools::build(vignettes=FALSE)
# R CMD INSTALL --library=~/R/x86_64-pc-linux-gnu-library/3.6 ./jmseq_0.0.0.9000.tar.gz

```

Joint modelling of longitudinal and time to event data can be efficiently implemented by sequential Bayesian updating.  

This vignette demonstrates an approximate two-step procedure, in which a linear Gaussian state space model is fitted to the longitudinal data, latent states at the start of each person-time interval are sampled from the forward updates generated by the Kalman filter, and these latent state values are plugged into a Poisson regression model for the event status at the end of each person-time interval.  


```{r setup, eval=TRUE}
library(jmseq)
library(data.table)

poissonglm.model <- rstan::stan_model(file="jmseq/stan/poissonglm.stan")
 
opt_evalall <- TRUE # set this to TRUE to evaluate all code in the Rmarkdown source

## Options
options(rmarkdown.html_vignette.check_title = FALSE)
knitr::opts_chunk$set(echo = TRUE)
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
ggplot2::theme_set(ggplot2::theme_light(base_size = 8))
```

# Dataset
The Mayo Clinic primary biliary cirrhosis dataset comprises 1945 longitudinal observations of two biomarkers -- bilirubin and albumin -- on 312 individuals followed for mortality up to 15 years from baseline. There are two time-invariant covariates: sex and age at baseline, with treatment as an extra time-invariant covariate included in the survival dataset. 

```{r pbc, eval=TRUE}
data(pbc, package="jmseq")
pbc
list2env(pbc, envir=environment())

#include event in long data
surv2 <- copy(dataSurv)
setnames(surv2,'Time.cens','Time')
dataLong <- merge(dataLong,surv2,all=TRUE)
dataLong[,FinalObs := c(rep(0,.N-1),1),by=id]
dataLong[FinalObs==0,event:= 0]
dataLong[,trt:=trt[!is.na(trt)],by=id]

nfolds <- 4
landmark.time <- 5
maxtime <- 15
set.seed <- 1234

```

## Test-training split for cross-validation
For cross-validation of the prediction of events, we split the dataset into test and training folds.  Each test fold contains all observations after the landmark time on the individuals in that test fold.  Each training fold contains all observations up to the landmark time and observations after the landmark time in those individuals who are not in the corresponding test fold. 


```{r split, eval=opt_evalall}
## minimum interval between biomarker observations as guide to setting timestep
dataLong.melted <- data.table::melt(data=dataLong, id.vars=c("id", "Time"), measure.vars=biomarkers)
dataLong.melted <- na.omit(dataLong.melted)
data.table::setorder(dataLong.melted, Time)
min.diff <- min(dataLong.melted[, diff(Time), by=list(id, variable)][["V1"]])
cat("Minimum interval between biomarker observations", min.diff, "\n")

timestep <- 60 / 365.25

rows.tosample <- which(dataSurv$Time > landmark.time) # & dataSurv$Time < max(dataSurv$Time))
rows.permuted <- base::sample(rows.tosample)
## test-train split for nfold cross-validation
folds <- cut(1:length(rows.permuted), breaks=nfolds, labels=FALSE)

## create list of ids in each testfolds 
ids.test <- vector("list", nfolds)
for(i in 1:nfolds) {
    ids.test[[i]] <- dataSurv[rows.permuted[folds==i], id]
}

## create training datasets
train.datasets <- vector("list", nfolds)
for(i in 1:nfolds) {
    train.datasets[[i]] <- vector("list", 3)
    names(train.datasets[[i]]) <- c("Surv", "Long", "ids.test")
    train.datasets[[i]]$Surv <- trainsplit.surv(ids.test=ids.test[[i]],
                                                dataSurv=dataSurv,
                                                landmark.time=landmark.time) 
    train.datasets[[i]]$Long <- trainsplit.long(ids.test[[i]],
                                                train.datasets[[i]]$Surv,
                                                dataLong, landmark.time,
                                                biomarkers)
    train.datasets[[i]]$ids.test <- ids.test[[i]]
}
```

# Models for the longitudinal data
We compare two models for the biomarker data: a linear mixed model with random slopes, and a more general model with random slopes, autoregressive drift, and diffusion (Wiener process). 

```{r listmodels, eval=opt_evalall}
## create list of models
models.list <- listmodels(biomarkers, timeinvar.long)[c(1, 5)]

```

## Fitting the longitudinal models to training folds
Next we run `ctsem` to fit each of these models to each training fold. The fitted models are saved in `fitted.list`. 

This step is parallelised using `parLapply`. 


```{r train, eval=opt_evalall}
## mclapply and foreach %dopar% fail -- child processes cannot open sockets
start <- Sys.time()
cl <- makePSOCKcluster(8)
fitted.list <- vector("list", length(models.list))
names(fitted.list) <- names(models.list)
cat("Looping over ctsem models to fit to training datasets ...\n")
for(m in 1:length(models.list)) {
    fitted.list[[m]] <- 
     #lapply(X=train.datasets, FUN=ctstanfit.fold, ctmodel=models.list[[m]]) 
     parLapply(cl, X=train.datasets, fun=ctstanfit.fold, ctmodel=models.list[[m]]) 
     gc()
    names(fitted.list[[m]]) <- paste0("fold", 1:nfolds)
}
stopCluster(cl)
cat("done, time ", difftime(Sys.time(), start, "mins"), "minutes\n")
```

## Comparison of longitudinal models
Comparing the fit of the model with drift, diffusion and random slopes to the linear mixed model shows that the model with drift and diffusion has much higher log-likelihood and lower AIC.  


```{r compare, eval=TRUE}
compare <- NULL
for(m in 1:length(fitted.list)) {
        s <- summary(fitted.list[[m]][[1]])
        compare <- rbind(compare,
                         data.frame(loglik=s$loglik, npars=s$npars, aic=s$aic))
}

knitr::kable(data.table(model=names(models.list), compare))

```

# Forward updates of the latent state values with the Kalman filter

## Example with five individuals

```{r plotfilter, eval=TRUE, fig.width=6}
## plot imputed values for first five individuals
ctsem::ctKalman(fit=fitted.list[[length(fitted.list)]][[1]], kalmanvec=c("y", "yprior"),
         subjects=1:5, plot=TRUE)
```

## Imputing latent state values over all person-time intervals 
Next we generate imputed values of the latent state variables from the forward updates of the state probabilities computed by the Kalman filter.  In each training fold, the forward updates continue to the end of the follow-up period including the person-time intervals in the test fold, where the biomarker observations have been dropped.  

This step is parallelised using `mcmapply`. 


```{r impute, eval=opt_evalall}
## generate imputations from each training fold within each ctsem model 
start <- Sys.time()
cat("Looping over ctsem models to generate imputations from Kalman filter ...\n")
kalwide.list <- vector("list", length(models.list))
names(kalwide.list) <- names(models.list)
for(m in 1:length(models.list)) {
    kalwide.list[[m]] <- mcmapply(FUN=kalmanwide,
                                fitted.list[[m]],
                                MoreArgs=list(timestep=timestep,
                                              maxtime=maxtime),
                                SIMPLIFY=FALSE)
}
cat("done, time ",  difftime(Sys.time(), start, "mins"), "minutes\n")
```

# Using imputed latent state values in a Poisson regression model for event status 
These  latent state values at the start of the interval are plugged into a Poisson regression model for the event status at the end of each interval. 


```{r poisson, eval=opt_evalall}

## fit Poisson model to training datasets for each fold within each ctsem model
poisson.glm.train <- vector("list", length(models.list))
for(m in 1:length(models.list)) {
    poisson.glm.train[m] <- vector("list", length(nfolds))
    for(fold in 1:nfolds) {
        poisson.glm.train[[m]][[fold]] <- fit.poissontsplit(kalwide.list[[m]][[fold]],
                                                   train.datasets[[fold]]$Surv,
                                                   timeinvar.surv, biomarkers, splines=FALSE)
    }
}
names(poisson.glm.train) <- names(models.list)

```

A table of the regression coefficients for the linear mixed model fitted to the first training fold is shown below. 

```{r printcoeffs, eval=TRUE}

## print coefficients for first model fitted to first training fold
coeffs <- poisson.glm.train[[1]][[1]]
coeffs <- data.table(Effect=names(coeffs), coeffs)
knitr::kable(coeffs,
      digits=c(0, 2),
      caption="Poisson time-splitting model fitted to latent biomarker values imputed by Kalman filter from linear mixed model with diffusion and drift")

```

## Prediction of event status on test folds
The next step is to generate predictions of event status on the test folds. Predictive performance is evaluated by concatenating observed and predicted event status over all test folds.  

```{r predict, eval=opt_evalall}
## generate predictions on test folds 
## elements of testdata.list are concatenations of all test folds 
testdata.list <- vector("list", length(models.list))
for(m in 1:length(models.list)) {
    testdata.model.list <- mapply(FUN=test.imputed,
                                   poisson.glm.train[[m]],
                                   ids.test,
                                   kalwide.list[[m]],
                                   MoreArgs=list(dataSurv=dataSurv,
                                                 landmark.time,
                                                 timeinvar.surv,
                                                 biomarkers),
                           SIMPLIFY=FALSE)
    testdata.list[[m]] <- data.table::rbindlist(testdata.model.list)
}
names(testdata.list) <- names(models.list)

## generate summary table of predictive performance
predict.table <- NULL
for(i in 1:length(testdata.list)) {
    stats <- tabulate.predictions(testdata.list[[i]])
    predict.table <- rbind(predict.table, stats)
}
predict.table <- data.table(Model=names(testdata.list), predict.table)
predict.table[, Predicted := as.numeric(Predicted)]
predict.table[, `Person-years` := as.numeric(`Person-years`)]
predict.table [, `Log score` := as.numeric(`Log score`)]
predict.table[, `C-statistic` := as.numeric(`C-statistic`)]

```

The fit of the longitudinal submodels, and the cross-validated predictive performance of the event submodels, are summarised in a table. 

```{r tablemodels, eval=TRUE}

knitr::kable(predict.table)

```
